{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTvr4_sti9Am"
      },
      "source": [
        "# Inroduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm8HKcygh4L2"
      },
      "source": [
        "This sample notebook demonstrates how to process live data streams using Pathway. The dataset used here is a subset of the one provided â€” specifically, it includes data for only a single parking spot. You are expected to implement your model across all parking spots.\n",
        "\n",
        "Please note that the pricing model used in this notebook is a simple baseline. You are expected to design and implement a more advanced and effective model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlwkKnB50IGF"
      },
      "outputs": [],
      "source": [
        "!pip install pathway bokeh --quiet # This cell may take a few seconds to execute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHuc1nkJveN3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "from datetime import datetime\n",
        "import pathway as pw\n",
        "import bokeh.plotting\n",
        "import panel as pn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGpZl1FxjFXE"
      },
      "source": [
        "# Step 1: Importing and Preprocessing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4D6geoV9veN3"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/dataset.csv')\n",
        "places = df['SystemCodeNumber'].unique()\n",
        "places\n",
        "\n",
        "# You can find the sample dataset here: https://drive.google.com/file/d/1D479FLjp9aO3Mg8g6Lpj9oRViWacurA6/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QBrvlQTjveN4"
      },
      "outputs": [],
      "source": [
        "# Combine the 'LastUpdatedDate' and 'LastUpdatedTime' columns into a single datetime column\n",
        "df['Timestamp'] = pd.to_datetime(df['LastUpdatedDate'] + ' ' + df['LastUpdatedTime'],\n",
        "                                  format='%d-%m-%Y %H:%M:%S')\n",
        "\n",
        "# Sort the DataFrame by the new 'Timestamp' column and reset the index\n",
        "df = df.sort_values('Timestamp').reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "c52UkGGpveN5"
      },
      "outputs": [],
      "source": [
        "# Save the selected columns to a CSV file for streaming or downstream processing\n",
        "df[[\"SystemCodeNumber\",\"Timestamp\", \"Occupancy\", \"Capacity\"]].to_csv(\"parking_stream.csv\", index=False)\n",
        "\n",
        "# Note: Only three features are used here for simplicity.\n",
        "# Participants are expected to incorporate additional relevant features in their models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "H0pe3TGIyKJE"
      },
      "outputs": [],
      "source": [
        "# Define the schema for the streaming data using Pathway\n",
        "# This schema specifies the expected structure of each data row in the stream\n",
        "\n",
        "class ParkingSchema(pw.Schema):\n",
        "    SystemCodeNumber : str\n",
        "    Timestamp: str   # Timestamp of the observation (should ideally be in ISO format)\n",
        "    Occupancy: int   # Number of occupied parking spots\n",
        "    Capacity: int    # Total parking capacity at the location\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "a4LxMh4xziMv"
      },
      "outputs": [],
      "source": [
        "# Load the data as a simulated stream using Pathway's replay_csv function\n",
        "# This replays the CSV data at a controlled input rate to mimic real-time streaming\n",
        "# input_rate=1000 means approximately 1000 rows per second will be ingested into the stream.\n",
        "\n",
        "data = pw.demo.replay_csv(\"parking_stream.csv\", schema=ParkingSchema, input_rate=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IkBP_AA-zjec"
      },
      "outputs": [],
      "source": [
        "# Define the datetime format to parse the 'Timestamp' column\n",
        "fmt = \"%Y-%m-%d %H:%M:%S\"\n",
        "\n",
        "# Add new columns to the data stream:\n",
        "# - 't' contains the parsed full datetime\n",
        "# - 'day' extracts the date part and resets the time to midnight (useful for day-level aggregations)\n",
        "data_with_time = data.with_columns(\n",
        "    t = data.Timestamp.dt.strptime(fmt),\n",
        "    day = data.Timestamp.dt.strptime(fmt).dt.strftime(\"%Y-%m-%dT00:00:00\")\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNDR7r4DqkhI"
      },
      "source": [
        "# Step 2: Making a simple pricing function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MznsSjanveN5"
      },
      "outputs": [],
      "source": [
        "# Define a daily tumbling window over the data stream using Pathway\n",
        "# This block performs temporal aggregation and computes a dynamic price for each day\n",
        "import datetime\n",
        "\n",
        "delta_window = (\n",
        "    data_with_time\n",
        "    .windowby(\n",
        "        pw.this.t,  # Event time column to use for windowing (parsed datetime)\n",
        "        instance=pw.this.day,  # Logical partitioning key: one instance per calendar day\n",
        "        window=pw.temporal.tumbling(datetime.timedelta(days=1)),  # Fixed-size daily window\n",
        "        behavior=pw.temporal.exactly_once_behavior()  # Guarantees exactly-once processing semantics\n",
        "    )\n",
        "    .groupby(pw.this.SystemCodeNumber)\n",
        "    .reduce(\n",
        "        SystemCodeNumber = pw.reducers.argmax(pw.this.t, pw.this.SystemCodeNumber),\n",
        "        occupancy = pw.reducers.argmax(pw.this.t, pw.this.Occupancy),\n",
        "        capacity = pw.reducers.argmax(pw.this.t, pw.this.Capacity),\n",
        "        t = pw.reducers.argmax(pw.this.t, pw.this.t),\n",
        "        day = pw.reducers.argmax(pw.this.t, pw.this.day),\n",
        "    )\n",
        ")\n",
        "\n",
        "delta_window\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQdi6PfbkewK"
      },
      "outputs": [],
      "source": [
        "pw.io.csv.write(delta_window, '/content/output.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWIXQoFmhZvL"
      },
      "outputs": [],
      "source": [
        "# Start the Pathway pipeline execution in the background\n",
        "# - This triggers the real-time data stream processing defined above\n",
        "# - %%capture --no-display suppresses output in the notebook interface\n",
        "\n",
        "%%capture --no-display\n",
        "pw.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diPma6HPknwe"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/output.csv')\n",
        "df['t'] = pd.to_datetime(df['t'])\n",
        "df['price'] = 10\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkZJ7VD_lZMQ"
      },
      "outputs": [],
      "source": [
        "for place in places:\n",
        "   mask = df['SystemCodeNumber'] == place\n",
        "   df_1 = df[mask]\n",
        "   data = df_1.copy().reset_index(drop=True)\n",
        "\n",
        "\n",
        "#Update prices row-by-row using previous row\n",
        "   for i in range(1, len(data)):\n",
        "    prev_price = data.loc[i - 1, 'price']\n",
        "    prev_occ = data.loc[i-1, 'occupancy']\n",
        "    prev_cap = data.loc[i-1, 'capacity']\n",
        "    occ = data.loc[i, 'occupancy']\n",
        "    cap = data.loc[i, 'capacity']\n",
        "    if (occ/cap) < (prev_occ/prev_cap):\n",
        "      alpha = -0.2\n",
        "    else:\n",
        "      alpha = 0.2\n",
        "\n",
        "    data.loc[i, 'price'] = prev_price + alpha * (occ / cap)\n",
        "\n",
        "\n",
        "\n",
        "   df.loc[mask, 'price'] = data['price'].values\n",
        "\n",
        "\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3sMSFtUqvax"
      },
      "source": [
        "# Step 3: Visualizing Daily Price Fluctuations with a Bokeh Plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POd-S7QMo9JA"
      },
      "source": [
        "**Note:** The Bokeh plot in the next cell will only be generated after you run the `pw.run()` cell (i.e., the final cell).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtBCKxmUYSgx"
      },
      "outputs": [],
      "source": [
        "from bokeh.io import output_file, show\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.io import curdoc\n",
        "from bokeh.plotting import ColumnDataSource, figure, output_file, show\n",
        "\n",
        "\n",
        "# print(df)\n",
        "output_file(\"dashboard.html\")\n",
        "\n",
        "curdoc().theme = 'dark_minimal'\n",
        "\n",
        "\n",
        "def plot_price_fluctuations(df, place):\n",
        "\n",
        "   curdoc().theme = 'dark_minimal'\n",
        "   p = figure(title=place ,width=1000, height=400, x_axis_type=\"datetime\")\n",
        "   p.line(df.t, df.price)\n",
        "   p.scatter(df.t, df.price, fill_color=\"red\", size=5)\n",
        "   return p\n",
        "\n",
        "panels = {}\n",
        "for idx, lot in enumerate(places):\n",
        "    lot_data = df[(df.SystemCodeNumber == lot)]\n",
        "    viz = plot_price_fluctuations(lot_data, lot)\n",
        "    panels[lot] = viz\n",
        "\n",
        "dashboard = pn.Tabs(*[(str(lot), panel) for lot, panel in panels.items()])\n",
        "\n",
        "dashboard.servable()  # Use .show() for Jupyter/Colab, or .servable() for Panel server\n",
        "\n",
        "\n",
        "# for place in places:\n",
        "#    plot_price_fluctuations(df[df['SystemCodeNumber'] == place], place)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 7749157,
          "sourceId": 12294858,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31040,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}